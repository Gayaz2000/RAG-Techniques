{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4001f593",
   "metadata": {},
   "source": [
    "# HyDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfbd01cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bba341a",
   "metadata": {},
   "source": [
    "#LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54523cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\", max_tokens=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d2b63b",
   "metadata": {},
   "source": [
    "#Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba272982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_t_with_space(list_of_documents):\n",
    "    \"\"\"\n",
    "        Replace all the tab ('\\t') keys with white space in the page content of list of documents.\n",
    "\n",
    "        Args:\n",
    "            list_of_documents: A list of document obj, each with 'page_content' attribute.\n",
    "        Return:\n",
    "            The modified list of documents with tab characters replaced by white spaces\n",
    "    \"\"\"\n",
    "    for doc in list_of_documents:\n",
    "        doc.page_content = doc.page_content.replace('\\t', \" \")\n",
    "    return list_of_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7b36036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "#from helper_functions import Helpers\n",
    "\n",
    "class Data_Ingestion_Pipe:\n",
    "    \"\"\"\n",
    "    A pipeline that showcases the ingestion of documet data into vectorstore\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path: str = r\"D:\\My Files\\RAG-Techniques\\RAG.pdf\"):\n",
    "        self.file_path = file_path\n",
    "        #self.helper_func = Helpers()\n",
    "        #self.embed_provider = Embedding_Provider()\n",
    "\n",
    "    \n",
    "    async def encode_pdf(self, chunk_size: int =1000, chunk_overlap: int = 200):\n",
    "        \"\"\"\n",
    "        Set of setps to stores the pdf documents in vectorestore in the form of embeddings\n",
    "        Args:\n",
    "            file_path: denotes the location of the file\n",
    "            chunk_size : denote the size of each chunk the document to be split into\n",
    "            chunk_overlap: connecting words in each chunk\n",
    "\n",
    "        Return:\n",
    "            A FAISS vector store containing the encoded book content.\n",
    "        \"\"\"\n",
    "        #loads the pdf file\n",
    "        try:\n",
    "            loader = PyPDFLoader(self.file_path)\n",
    "            docs = await loader.aload()\n",
    "        except FileNotFoundError as e:\n",
    "            raise f\"Error occured: {e}\"\n",
    "        # split the doc file into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size = chunk_size, chunk_overlap = chunk_overlap\n",
    "        )\n",
    "        doc_chunks = text_splitter.split_documents(documents=docs)\n",
    "\n",
    "        cleaned_texts = replace_t_with_space(doc_chunks)\n",
    "        #embeddings\n",
    "        embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        #vector db\n",
    "        faiss_vstore = await FAISS.afrom_documents(cleaned_texts, embedding=embedding)\n",
    "        return faiss_vstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dac2cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96f73ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def doc_retriever(chunk_size=500, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    retrieves top k similar documents\n",
    "    \"\"\"\n",
    "    obj = Data_Ingestion_Pipe()\n",
    "    vstore = await obj.encode_pdf(chunk_size=500, chunk_overlap=100)\n",
    "    #retriever = await vstore.aas_retriever(search_kwargs={\"k\": 3})\n",
    "    return vstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ea35ba",
   "metadata": {},
   "source": [
    "#HyDE Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b743cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "class HyDERetriever:\n",
    "    def __init__(self, chunk_size=500, chunk_overlap=100):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.llm = llm  \n",
    "        self.vectorestore = asyncio.run(doc_retriever())\n",
    "\n",
    "        self.hyde_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"chunk_size\"],\n",
    "            template=\"\"\"Given the question '{query}', generate a hypothetical document that directly answers this question. The document should be detailed and in-depth.\n",
    "            the document size has be exactly {chunk_size} characters.\"\"\",\n",
    "        )\n",
    "        self.hyde_chain = self.hyde_prompt | self.llm\n",
    "    \n",
    "    async def generate_hypothetical_document(self, query):\n",
    "        \"\"\"Generates a HyDE from query\"\"\"\n",
    "        input_variables = {\"query\": query, \"chunk_size\": self.chunk_size}\n",
    "        return await self.hyde_chain.ainvoke(input_variables)\n",
    "    \n",
    "    async def retriever(self, query, k=3):\n",
    "        \"\"\"Retrieves context form Vector DB using HyDE documents\"\"\"\n",
    "        hypothetical_docs = asyncio.run(self.generate_hypothetical_document(query)).content\n",
    "        similar_docs = await self.vectorestore.asimilarity_search(hypothetical_docs, k=k)\n",
    "        return similar_docs, hypothetical_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9042970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = HyDERetriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea6c8cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"What is HyDE in RAG?\"\n",
    "results, hypothetical_doc = asyncio.run(retriever.retriever(test_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b013ad5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothetical_doc:\n",
      "\n",
      "**HyDE in RAG: A Comprehensive Overview**\n",
      "\n",
      "HyDE, short for Hydrological Data Extraction, is a Raster Application Framework (RAG) tool designed to extract and process large-scale hydrological data from gridded datasets. Developed by the European Space Agency (ESA), HyDE enables users to retrieve and analyze hydrological parameters such as evapotranspiration, soil moisture, and runoff at a high spatial and temporal resolution.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "1. **Data Retrieval:** HyDE allows users to download and process gridded hydrological data from various sources, including the ESA's Climate Change Initiative (CCI) and the Copernicus Climate Data Store (CDS).\n",
      "2. **Data Processing:** The tool performs complex calculations, such as downscaling, aggregating, and interpolating data to create high-resolution hydrological products.\n",
      "3. **Customization:** Users can tailor their output by selecting specific data products, temporal resolutions, and spatial extent.\n",
      "4. **Visualization:** HyDE provides an integrated visualization module for exploring and analyzing the extracted data.\n",
      "\n",
      "**Applications:**\n",
      "\n",
      "1. **Water Resources Management:** HyDE's high-resolution hydrological data supports water resources planning, flood risk management, and drought monitoring.\n",
      "2. **Agricultural Applications:** The tool's evapotranspiration and soil moisture products aid in crop yield prediction, irrigation management, and agricultural research.\n",
      "3. **Climate Modeling:** HyDE's data can be used to evaluate and improve climate models, as well as study the impacts of climate change on hydrological processes.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "HyDE in RAG is a powerful tool for extracting, processing, and analyzing large-scale hydrological data. Its versatility and customization options make it an essential resource for researchers, policymakers, and practitioners working in the fields of hydrology, agriculture, and climate science.\n",
      "\n",
      "['4.4 Fact Veriﬁcation\\nTable 2 shows our results on FEVER. For 3-way classiﬁcation, RAG scores are within 4.3% of\\nstate-of-the-art models, which are complex pipeline systems with domain-speciﬁc architectures and\\nsubstantial engineering, trained using intermediate retrieval supervision, which RAG does not require.\\n6', 'Transformers [66]3, which achieves equivalent performance to the previous version but is a cleaner\\nand easier to use implementation. This version is also open-sourced. We also compress the document\\nindex using FAISS’s compression tools, reducing the CPU memory requirement to 36GB. Scripts to\\nrun experiments with RAG can be found athttps://github.com/huggingface/transformers/\\nblob/master/examples/rag/README.md and an interactive demo of a RAG model can be found\\nat https://huggingface.co/rag/', 'Wikipedia dump from December 2016 and compare outputs from RAG using this index to the newer\\nindex from our main results (December 2018). We prepare a list of 82 world leaders who had changed\\n7']\n"
     ]
    }
   ],
   "source": [
    "docs_content = [doc.page_content for doc in results]\n",
    "\n",
    "print(\"hypothetical_doc:\\n\")\n",
    "print((hypothetical_doc)+\"\\n\")\n",
    "print(docs_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a034c728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
