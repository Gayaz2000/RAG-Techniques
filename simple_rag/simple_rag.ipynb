{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f3855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"Simple RAG\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa91f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_t_with_space(list_of_documents):\n",
    "    \"\"\"\n",
    "        Replace all the tab ('\\t') keys with white space in the page content of list of documents.\n",
    "\n",
    "        Args:\n",
    "            list_of_documents: A list of document obj, each with 'page_content' attribute.\n",
    "        Return:\n",
    "            The modified list of documents with tab characters replaced by white spaces\n",
    "    \"\"\"\n",
    "    for doc in list_of_documents:\n",
    "        doc.page_content = doc.page_content.replace('\\t', \" \")\n",
    "    return list_of_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9330619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "#from helper_functions import Helpers\n",
    "\n",
    "class Data_Ingestion_Pipe:\n",
    "    \"\"\"\n",
    "    A pipeline that showcases the ingestion of documet data into vectorstore\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path: str = r\"D:\\My Files\\RAG-Techniques\\RAG.pdf\"):\n",
    "        self.file_path = file_path\n",
    "        #self.helper_func = Helpers()\n",
    "        #self.embed_provider = Embedding_Provider()\n",
    "    \n",
    "    def encode_pdf(self, chunk_size: int =1000, chunk_overlap: int = 200):\n",
    "        \"\"\"\n",
    "        Set of setps to stores the pdf documents in vectorestore in the form of embeddings\n",
    "        Args:\n",
    "            file_path: denotes the location of the file\n",
    "            chunk_size : denote the size of each chunk the document to be split into\n",
    "            chunk_overlap: connecting words in each chunk\n",
    "\n",
    "        Return:\n",
    "            A FAISS vector store containing the encoded book content.\n",
    "        \"\"\"\n",
    "        #loads the pdf file\n",
    "        try:\n",
    "            loader = PyPDFLoader(self.file_path)\n",
    "            docs = loader.load()\n",
    "        except FileNotFoundError as e:\n",
    "            raise f\"Error occured: {e}\"\n",
    "        # split the doc file into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size = chunk_size, chunk_overlap = chunk_overlap\n",
    "        )\n",
    "        doc_chunks = text_splitter.split_documents(documents=docs)\n",
    "        cleaned_texts = replace_t_with_space(doc_chunks)\n",
    "        #embeddings\n",
    "        embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        #vector db\n",
    "        faiss_vstore = FAISS.from_documents(cleaned_texts, embedding=embedding)\n",
    "        return faiss_vstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5850c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_retriever(vstore, k):\n",
    "    \"\"\"\n",
    "    retrieves top k similar documents\n",
    "    \"\"\"\n",
    "    retriever =  vstore.as_retriever(search_kwargs={\"k\": k})\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c31486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from helper_functions import show_context\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     question = input(\"Enter the retrieval query: \")\n",
    "#     vstore = Data_Ingestion_Pipe().encode_pdf() ### add chunk_size and chunk_overlap\n",
    "#     retriever = doc_retriever(vstore=vstore, k=2)\n",
    "#     docs = retriever.get_relevant_documents(question)\n",
    "#     result = [doc.page_content for doc in docs]\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "294a9849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langsmith import traceable\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\", temperature=1)\n",
    "question = input(\"Enter the retrieval query: \")\n",
    "# Add decorator so this function is traced in LangSmith\n",
    "@traceable()\n",
    "def rag_bot(question: str) -> dict:\n",
    "    # LangChain retriever will be automatically traced\n",
    "    vstore = Data_Ingestion_Pipe().encode_pdf()\n",
    "    retriever = doc_retriever(vstore=vstore, k=2)\n",
    "    docs = retriever.invoke(question)\n",
    "    docs_string = \" \".join(doc.page_content for doc in docs)\n",
    "\n",
    "    instructions = f\"\"\"You are a helpful assistant who is good at analyzing source information and answering questions.       Use the following source documents to answer the user's questions.       If you don't know the answer, just say that you don't know.       Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Documents:\n",
    "{docs_string}\"\"\"\n",
    "\n",
    "    # langchain ChatModel will be automatically traced\n",
    "    ai_msg = llm.invoke([\n",
    "            {\"role\": \"system\", \"content\": instructions},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return {\"answer\": ai_msg.content, \"documents\": docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4df11f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "LangSmithConflictError",
     "evalue": "Conflict for /datasets. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Dataset with this name already exists.\"}')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Files\\RAG-Techniques\\.venv\\Lib\\site-packages\\langsmith\\utils.py:154\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Files\\RAG-Techniques\\.venv\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Files\\RAG-Techniques\\.venv\\Lib\\site-packages\\langsmith\\client.py:840\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    834\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.session.request(\n\u001b[32m    835\u001b[39m         method,\n\u001b[32m    836\u001b[39m         _construct_url(\u001b[38;5;28mself\u001b[39m.api_url, pathname),\n\u001b[32m    837\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    838\u001b[39m         **request_kwargs,\n\u001b[32m    839\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m \u001b[43mls_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Files\\RAG-Techniques\\.venv\\Lib\\site-packages\\langsmith\\utils.py:156\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m requests.HTTPError(\u001b[38;5;28mstr\u001b[39m(e), response.text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mHTTPError\u001b[39m: [Errno 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets] {\"detail\":\"Dataset with this name already exists.\"}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mLangSmithConflictError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Create the dataset and examples in LangSmith\u001b[39;00m\n\u001b[32m     22\u001b[39m dataset_name = \u001b[33m\"\u001b[39m\u001b[33mLilian Weng Blogs Q&A\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m dataset = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m client.create_examples(\n\u001b[32m     25\u001b[39m     dataset_id=dataset.id,\n\u001b[32m     26\u001b[39m     examples=examples\n\u001b[32m     27\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Files\\RAG-Techniques\\.venv\\Lib\\site-packages\\langsmith\\client.py:3435\u001b[39m, in \u001b[36mClient.create_dataset\u001b[39m\u001b[34m(self, dataset_name, description, data_type, inputs_schema, outputs_schema, transformations, metadata)\u001b[39m\n\u001b[32m   3432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m outputs_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3433\u001b[39m     dataset[\u001b[33m\"\u001b[39m\u001b[33moutputs_schema_definition\u001b[39m\u001b[33m\"\u001b[39m] = outputs_schema\n\u001b[32m-> \u001b[39m\u001b[32m3435\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3436\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3437\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/datasets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3438\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mContent-Type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3439\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_orjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3440\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3441\u001b[39m ls_utils.raise_for_status_with_text(response)\n\u001b[32m   3443\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ls_schemas.Dataset(\n\u001b[32m   3444\u001b[39m     **response.json(),\n\u001b[32m   3445\u001b[39m     _host_url=\u001b[38;5;28mself\u001b[39m._host_url,\n\u001b[32m   3446\u001b[39m     _tenant_id=\u001b[38;5;28mself\u001b[39m._get_optional_tenant_id(),\n\u001b[32m   3447\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\My Files\\RAG-Techniques\\.venv\\Lib\\site-packages\\langsmith\\client.py:885\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithNotFoundError(\n\u001b[32m    881\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResource not found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    882\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m     )\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m409\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithConflictError(\n\u001b[32m    886\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConflict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    887\u001b[39m     )\n\u001b[32m    888\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    889\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithError(\n\u001b[32m    890\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in LangSmith\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    891\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m API. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    892\u001b[39m     )\n",
      "\u001b[31mLangSmithConflictError\u001b[39m: Conflict for /datasets. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Dataset with this name already exists.\"}')"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# Define the examples for the dataset\n",
    "examples = [\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"How does the ReAct agent use self-reflection? \"},\n",
    "        \"outputs\": {\"answer\": \"ReAct integrates reasoning and acting, performing actions - such tools like Wikipedia search API - and then observing / reasoning about the tool outputs.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What are the types of biases that can arise with few-shot prompting?\"},\n",
    "        \"outputs\": {\"answer\": \"The biases that can arise with few-shot prompting include (1) Majority label bias, (2) Recency bias, and (3) Common token bias.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What are five types of adversarial attacks?\"},\n",
    "        \"outputs\": {\"answer\": \"Five types of adversarial attacks are (1) Token manipulation, (2) Gradient based attack, (3) Jailbreak prompting, (4) Human red-teaming, (5) Model red-teaming.\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create the dataset and examples in LangSmith\n",
    "dataset_name = \"Lilian Weng Blogs Q&A\"\n",
    "dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "client.create_examples(\n",
    "    dataset_id=dataset.id,\n",
    "    examples=examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4afe8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Grade output schema\n",
    "class CorrectnessGrade(TypedDict):\n",
    "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
    "    correct: Annotated[bool, ..., \"True if the answer is correct, False otherwise.\"]\n",
    "\n",
    "# Grade prompt\n",
    "correctness_instructions = \"\"\"You are a teacher grading a quiz. \n",
    "\n",
    "You will be given a QUESTION, the GROUND TRUTH (correct) ANSWER, and the STUDENT ANSWER. \n",
    "\n",
    "Here is the grade criteria to follow:\n",
    "(1) Grade the student answers based ONLY on their factual accuracy relative to the ground truth answer. \n",
    "(2) Ensure that the student answer does not contain any conflicting statements.\n",
    "(3) It is OK if the student answer contains more information than the ground truth answer, as long as it is factually accurate relative to the  ground truth answer.\n",
    "\n",
    "Correctness:\n",
    "A correctness value of True means that the student's answer meets all of the criteria.\n",
    "A correctness value of False means that the student's answer does not meet all of the criteria.\n",
    "\n",
    "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. \n",
    "\n",
    "Avoid simply stating the correct answer at the outset.\"\"\"\n",
    "\n",
    "# Grader LLM\n",
    "grader_llm = ChatGroq(model=\"gemma2-9b-it\", temperature=0).with_structured_output(CorrectnessGrade, method=\"json_schema\", strict=True)\n",
    "\n",
    "def correctness(inputs: dict, outputs: dict, reference_outputs: dict) -> bool:\n",
    "    \"\"\"An evaluator for RAG answer accuracy\"\"\"\n",
    "    answers = f\"\"\"\\\n",
    "QUESTION: {inputs['question']}\n",
    "GROUND TRUTH ANSWER: {reference_outputs['answer']}\n",
    "STUDENT ANSWER: {outputs['answer']}\"\"\"\n",
    "\n",
    "    # Run evaluator\n",
    "    grade = grader_llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": correctness_instructions}, \n",
    "        {\"role\": \"user\", \"content\": answers}\n",
    "    ])\n",
    "    return grade[\"correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f029612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'rag-doc-relevance-64afe964' at:\n",
      "https://smith.langchain.com/o/b30f5232-cf83-47ae-9e6c-8156860113d4/datasets/b7114e3e-eb43-4b5e-8a0a-41f10b48b3b6/compare?selectedSessions=a1c4318d-cb1a-4f48-8351-a18c5718497b\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:19, 26.46s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "def target(inputs: dict) -> dict:\n",
    "    return rag_bot(inputs[\"question\"])\n",
    "\n",
    "experiment_results = client.evaluate(\n",
    "    target,\n",
    "    data=dataset_name,\n",
    "    evaluators=[correctness], #groundedness, relevance, retrieval_relevance\n",
    "    experiment_prefix=\"rag-doc-relevance\",\n",
    "    metadata={\"version\": \"LCEL context, gemma2-9b-it-preview\"},\n",
    ")\n",
    "# Explore results locally as a dataframe if you have pandas installed\n",
    "experiment_results.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0deef1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
